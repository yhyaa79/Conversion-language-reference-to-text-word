{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists: /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video\n",
      "Folder already exists: /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images\n",
      "Folder already exists: /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/3_square_images\n",
      "Folder already exists: /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/4_resized_images\n",
      "Folder already exists: /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/yolov5/runs/train/weights/best.pt\n",
      "Folder already exists: /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset\n",
      "Deleted folder: /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/yolov5/runs/detect/exp\n",
      "Command Output: \n",
      "Command Error: /Users/yayhaeslami/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/yolov5/runs/train/weights/best.pt'], source=/Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4, data=preparing_dataset/yolov5/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.4, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=preparing_dataset/yolov5/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5 🚀 v7.0-315-g892e8a82 Python-3.11.5 torch-2.3.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 1761871 parameters, 0 gradients, 4.1 GFLOPs\n",
      "video 1/1 (1/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 91.5ms\n",
      "video 1/1 (2/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 84.0ms\n",
      "video 1/1 (3/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 89.6ms\n",
      "video 1/1 (4/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 131.9ms\n",
      "video 1/1 (5/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 128.9ms\n",
      "video 1/1 (6/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 106.5ms\n",
      "video 1/1 (7/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 96.3ms\n",
      "video 1/1 (8/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 96.4ms\n",
      "video 1/1 (9/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 91.5ms\n",
      "video 1/1 (10/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 89.7ms\n",
      "video 1/1 (11/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 88.3ms\n",
      "video 1/1 (12/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 85.3ms\n",
      "video 1/1 (13/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 87.5ms\n",
      "video 1/1 (14/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 91.4ms\n",
      "video 1/1 (15/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 89.4ms\n",
      "video 1/1 (16/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 87.8ms\n",
      "video 1/1 (17/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 96.2ms\n",
      "video 1/1 (18/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 86.6ms\n",
      "video 1/1 (19/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 90.5ms\n",
      "video 1/1 (20/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 88.3ms\n",
      "video 1/1 (21/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 89.5ms\n",
      "video 1/1 (22/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 89.3ms\n",
      "video 1/1 (23/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 84.9ms\n",
      "video 1/1 (24/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 89.6ms\n",
      "video 1/1 (25/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 86.6ms\n",
      "video 1/1 (26/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 87.1ms\n",
      "video 1/1 (27/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 87.7ms\n",
      "video 1/1 (28/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 84.5ms\n",
      "video 1/1 (29/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 88.2ms\n",
      "video 1/1 (30/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 86.9ms\n",
      "video 1/1 (31/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 90.8ms\n",
      "video 1/1 (32/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 93.9ms\n",
      "video 1/1 (33/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 91.9ms\n",
      "video 1/1 (34/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 92.8ms\n",
      "video 1/1 (35/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 95.9ms\n",
      "video 1/1 (36/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 93.4ms\n",
      "video 1/1 (37/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 95.6ms\n",
      "video 1/1 (38/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 89.0ms\n",
      "video 1/1 (39/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 87.1ms\n",
      "video 1/1 (40/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 85.6ms\n",
      "video 1/1 (41/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 90.0ms\n",
      "video 1/1 (42/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 96.6ms\n",
      "video 1/1 (43/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 101.8ms\n",
      "video 1/1 (44/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 105.0ms\n",
      "video 1/1 (45/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 98.0ms\n",
      "video 1/1 (46/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 92.2ms\n",
      "video 1/1 (47/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 88.3ms\n",
      "video 1/1 (48/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 90.3ms\n",
      "video 1/1 (49/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 93.2ms\n",
      "video 1/1 (50/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 107.3ms\n",
      "video 1/1 (51/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 221.7ms\n",
      "video 1/1 (52/52) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 224.5ms\n",
      "Speed: 0.6ms pre-process, 98.0ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mpreparing_dataset/yolov5/runs/detect/exp\u001b[0m\n",
      "52 labels saved to preparing_dataset/yolov5/runs/detect/exp/labels\n",
      "\n",
      "52 frames extracted.\n",
      "Converted video_7.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_7.jpg\n",
      "Converted video_26.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_26.jpg\n",
      "Converted video_32.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_32.jpg\n",
      "Converted video_33.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_33.jpg\n",
      "Converted video_27.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_27.jpg\n",
      "Converted video_6.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_6.jpg\n",
      "Converted video_4.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_4.jpg\n",
      "Converted video_19.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_19.jpg\n",
      "Converted video_31.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_31.jpg\n",
      "Converted video_25.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_25.jpg\n",
      "Converted video_24.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_24.jpg\n",
      "Converted video_30.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_30.jpg\n",
      "Converted video_18.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_18.jpg\n",
      "Converted video_5.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_5.jpg\n",
      "Converted video_1.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_1.jpg\n",
      "Converted video_34.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_34.jpg\n",
      "Converted video_20.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_20.jpg\n",
      "Converted video_21.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_21.jpg\n",
      "Converted video_35.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_35.jpg\n",
      "Converted video_2.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_2.jpg\n",
      "Converted video_23.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_23.jpg\n",
      "Converted video_37.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_37.jpg\n",
      "Converted video_36.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_36.jpg\n",
      "Converted video_22.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_22.jpg\n",
      "Converted video_3.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_3.jpg\n",
      "Converted video_45.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_45.jpg\n",
      "Converted video_51.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_51.jpg\n",
      "Converted video_50.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_50.jpg\n",
      "Converted video_44.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_44.jpg\n",
      "Converted video_52.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_52.jpg\n",
      "Converted video_46.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_46.jpg\n",
      "Converted video_47.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_47.jpg\n",
      "Converted video_43.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_43.jpg\n",
      "Converted video_42.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_42.jpg\n",
      "Converted video_40.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_40.jpg\n",
      "Converted video_41.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_41.jpg\n",
      "Converted video_49.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_49.jpg\n",
      "Converted video_48.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_48.jpg\n",
      "Converted video_13.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_13.jpg\n",
      "Converted video_12.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_12.jpg\n",
      "Converted video_38.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_38.jpg\n",
      "Converted video_10.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_10.jpg\n",
      "Converted video_11.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_11.jpg\n",
      "Converted video_39.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_39.jpg\n",
      "Converted video_8.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_8.jpg\n",
      "Converted video_15.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_15.jpg\n",
      "Converted video_29.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_29.jpg\n",
      "Converted video_28.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_28.jpg\n",
      "Converted video_14.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_14.jpg\n",
      "Converted video_9.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_9.jpg\n",
      "Converted video_16.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_16.jpg\n",
      "Converted video_17.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_17.jpg\n",
      "Conversion completed.\n",
      "file '/Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/yolov5/runs/detect/exp/labels/video_1.txt' Successfully updated.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "best1: [0.283333 0.39213  0.153704 0.193519]\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "best1: [0.309722 0.4125   0.152778 0.175   ]\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "best1: [0.205093 0.404167 0.173148 0.199074]\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "Number of text files remaining in labels: 30\n",
      "Number of image files remaining in images: 30\n",
      "Resized and saved: video_1_1_1.jpg\n",
      "Resized and saved: video_16_3_0.jpg\n",
      "Resized and saved: video_8_3_0.jpg\n",
      "Resized and saved: video_30_1_1.jpg\n",
      "Resized and saved: video_20_1_1.jpg\n",
      "Resized and saved: video_15_2_1.jpg\n",
      "Resized and saved: video_29_3_0.jpg\n",
      "Resized and saved: video_1_3_0.jpg\n",
      "Resized and saved: video_8_1_1.jpg\n",
      "Resized and saved: video_23_2_1.jpg\n",
      "Resized and saved: video_16_1_1.jpg\n",
      "Resized and saved: video_20_3_0.jpg\n",
      "Resized and saved: video_30_3_0.jpg\n",
      "Resized and saved: video_2_2_1.jpg\n",
      "Resized and saved: video_29_1_1.jpg\n",
      "Resized and saved: video_17_1_1.jpg\n",
      "Resized and saved: video_9_1_1.jpg\n",
      "Resized and saved: video_22_2_1.jpg\n",
      "Resized and saved: video_21_3_0.jpg\n",
      "Resized and saved: video_3_2_1.jpg\n",
      "Resized and saved: video_28_1_1.jpg\n",
      "Resized and saved: video_9_3_0.jpg\n",
      "Resized and saved: video_17_3_0.jpg\n",
      "Resized and saved: video_14_2_1.jpg\n",
      "Resized and saved: video_21_1_1.jpg\n",
      "Resized and saved: video_28_3_0.jpg\n",
      "Resized and saved: video_15_1_1.jpg\n",
      "Resized and saved: video_30_2_1.jpg\n",
      "Resized and saved: video_20_2_1.jpg\n",
      "Resized and saved: video_2_3_0.jpg\n",
      "Resized and saved: video_1_2_1.jpg\n",
      "Resized and saved: video_23_3_0.jpg\n",
      "Resized and saved: video_15_3_0.jpg\n",
      "Resized and saved: video_29_2_1.jpg\n",
      "Resized and saved: video_2_1_1.jpg\n",
      "Resized and saved: video_16_2_1.jpg\n",
      "Resized and saved: video_23_1_1.jpg\n",
      "Resized and saved: video_8_2_1.jpg\n",
      "Resized and saved: video_14_3_0.jpg\n",
      "Resized and saved: video_28_2_1.jpg\n",
      "Resized and saved: video_3_1_1.jpg\n",
      "Resized and saved: video_22_1_1.jpg\n",
      "Resized and saved: video_9_2_1.jpg\n",
      "Resized and saved: video_17_2_1.jpg\n",
      "Resized and saved: video_21_2_1.jpg\n",
      "Resized and saved: video_14_1_1.jpg\n",
      "Resized and saved: video_3_3_0.jpg\n",
      "Resized and saved: video_22_3_0.jpg\n",
      "Resized and saved: video_5_2_1.jpg\n",
      "Resized and saved: video_27_3_0.jpg\n",
      "Resized and saved: video_24_2_1.jpg\n",
      "Resized and saved: video_11_1_1.jpg\n",
      "Resized and saved: video_18_3_0.jpg\n",
      "Resized and saved: video_6_3_0.jpg\n",
      "Resized and saved: video_27_1_1.jpg\n",
      "Resized and saved: video_12_2_1.jpg\n",
      "Resized and saved: video_11_3_0.jpg\n",
      "Resized and saved: video_6_1_1.jpg\n",
      "Resized and saved: video_18_1_1.jpg\n",
      "Resized and saved: video_13_2_1.jpg\n",
      "Resized and saved: video_26_1_1.jpg\n",
      "Resized and saved: video_10_3_0.jpg\n",
      "Resized and saved: video_19_1_1.jpg\n",
      "Resized and saved: video_7_1_1.jpg\n",
      "Resized and saved: video_4_2_1.jpg\n",
      "Resized and saved: video_26_3_0.jpg\n",
      "Resized and saved: video_10_1_1.jpg\n",
      "Resized and saved: video_25_2_1.jpg\n",
      "Resized and saved: video_7_3_0.jpg\n",
      "Resized and saved: video_19_3_0.jpg\n",
      "Resized and saved: video_11_2_1.jpg\n",
      "Resized and saved: video_24_1_1.jpg\n",
      "Resized and saved: video_5_1_1.jpg\n",
      "Resized and saved: video_12_3_0.jpg\n",
      "Resized and saved: video_24_3_0.jpg\n",
      "Resized and saved: video_18_2_1.jpg\n",
      "Resized and saved: video_6_2_1.jpg\n",
      "Resized and saved: video_5_3_0.jpg\n",
      "Resized and saved: video_12_1_1.jpg\n",
      "Resized and saved: video_27_2_1.jpg\n",
      "Resized and saved: video_25_3_0.jpg\n",
      "Resized and saved: video_7_2_1.jpg\n",
      "Resized and saved: video_19_2_1.jpg\n",
      "Resized and saved: video_4_3_0.jpg\n",
      "Resized and saved: video_26_2_1.jpg\n",
      "Resized and saved: video_13_1_1.jpg\n",
      "Resized and saved: video_25_1_1.jpg\n",
      "Resized and saved: video_10_2_1.jpg\n",
      "Resized and saved: video_4_1_1.jpg\n",
      "Resized and saved: video_13_3_0.jpg\n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data4/1.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data4/16.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data4/8.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data4/30.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data4/20.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data4/15.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data4/29.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data4/23.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data4/2.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data4/17.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data4/9.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data4/22.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data4/21.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data4/3.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data4/28.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data4/14.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data4/5.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data4/27.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data4/24.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data4/11.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data4/18.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data4/6.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data4/12.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data4/13.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data4/26.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data4/10.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data4/19.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data4/7.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data4/4.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data4/25.jpg  saved \n",
      "Deleted folder: /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/yolov5/runs/detect/exp\n",
      "Command Output: \n",
      "Command Error: /Users/yayhaeslami/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/yolov5/runs/train/weights/best.pt'], source=/Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4, data=preparing_dataset/yolov5/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.4, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=preparing_dataset/yolov5/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5 🚀 v7.0-315-g892e8a82 Python-3.11.5 torch-2.3.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 1761871 parameters, 0 gradients, 4.1 GFLOPs\n",
      "video 1/1 (1/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 97.6ms\n",
      "video 1/1 (2/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 88.1ms\n",
      "video 1/1 (3/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 82.7ms\n",
      "video 1/1 (4/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 83.4ms\n",
      "video 1/1 (5/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 108.9ms\n",
      "video 1/1 (6/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 129.4ms\n",
      "video 1/1 (7/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 106.7ms\n",
      "video 1/1 (8/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 112.5ms\n",
      "video 1/1 (9/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 95.6ms\n",
      "video 1/1 (10/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 91.0ms\n",
      "video 1/1 (11/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 87.3ms\n",
      "video 1/1 (12/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 91.6ms\n",
      "video 1/1 (13/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 94.7ms\n",
      "video 1/1 (14/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 167.1ms\n",
      "video 1/1 (15/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 107.7ms\n",
      "video 1/1 (16/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 109.6ms\n",
      "video 1/1 (17/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 123.5ms\n",
      "video 1/1 (18/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 104.8ms\n",
      "video 1/1 (19/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 114.3ms\n",
      "video 1/1 (20/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 107.4ms\n",
      "video 1/1 (21/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 108.0ms\n",
      "video 1/1 (22/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 95.4ms\n",
      "video 1/1 (23/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 88.8ms\n",
      "video 1/1 (24/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 85.8ms\n",
      "video 1/1 (25/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 89.2ms\n",
      "video 1/1 (26/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 114.2ms\n",
      "video 1/1 (27/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 102.2ms\n",
      "video 1/1 (28/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 92.3ms\n",
      "video 1/1 (29/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 100.1ms\n",
      "video 1/1 (30/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 182.1ms\n",
      "video 1/1 (31/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 107.1ms\n",
      "video 1/1 (32/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 92.1ms\n",
      "video 1/1 (33/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 90.3ms\n",
      "video 1/1 (34/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 83.5ms\n",
      "video 1/1 (35/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 85.2ms\n",
      "video 1/1 (36/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 83.4ms\n",
      "video 1/1 (37/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 84.9ms\n",
      "video 1/1 (38/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 98.0ms\n",
      "video 1/1 (39/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 98.8ms\n",
      "video 1/1 (40/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 88.9ms\n",
      "video 1/1 (41/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 93.0ms\n",
      "video 1/1 (42/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 90.7ms\n",
      "video 1/1 (43/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 87.8ms\n",
      "video 1/1 (44/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 88.2ms\n",
      "video 1/1 (45/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 86.8ms\n",
      "video 1/1 (46/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 90.7ms\n",
      "video 1/1 (47/47) /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4: 640x640 1 face, 2 hands, 83.2ms\n",
      "Speed: 0.6ms pre-process, 99.9ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mpreparing_dataset/yolov5/runs/detect/exp\u001b[0m\n",
      "47 labels saved to preparing_dataset/yolov5/runs/detect/exp/labels\n",
      "\n",
      "47 frames extracted.\n",
      "Converted video_7.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_7.jpg\n",
      "Converted video_26.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_26.jpg\n",
      "Converted video_32.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_32.jpg\n",
      "Converted video_33.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_33.jpg\n",
      "Converted video_27.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_27.jpg\n",
      "Converted video_6.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_6.jpg\n",
      "Converted video_4.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_4.jpg\n",
      "Converted video_19.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_19.jpg\n",
      "Converted video_31.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_31.jpg\n",
      "Converted video_25.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_25.jpg\n",
      "Converted video_24.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_24.jpg\n",
      "Converted video_30.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_30.jpg\n",
      "Converted video_18.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_18.jpg\n",
      "Converted video_5.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_5.jpg\n",
      "Converted video_1.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_1.jpg\n",
      "Converted video_34.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_34.jpg\n",
      "Converted video_20.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_20.jpg\n",
      "Converted video_21.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_21.jpg\n",
      "Converted video_35.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_35.jpg\n",
      "Converted video_2.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_2.jpg\n",
      "Converted video_23.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_23.jpg\n",
      "Converted video_37.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_37.jpg\n",
      "Converted video_36.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_36.jpg\n",
      "Converted video_22.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_22.jpg\n",
      "Converted video_3.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_3.jpg\n",
      "Converted video_45.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_45.jpg\n",
      "Converted video_44.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_44.jpg\n",
      "Converted video_46.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_46.jpg\n",
      "Converted video_47.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_47.jpg\n",
      "Converted video_43.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_43.jpg\n",
      "Converted video_42.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_42.jpg\n",
      "Converted video_40.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_40.jpg\n",
      "Converted video_41.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_41.jpg\n",
      "Converted video_13.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_13.jpg\n",
      "Converted video_12.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_12.jpg\n",
      "Converted video_38.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_38.jpg\n",
      "Converted video_10.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_10.jpg\n",
      "Converted video_11.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_11.jpg\n",
      "Converted video_39.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_39.jpg\n",
      "Converted video_8.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_8.jpg\n",
      "Converted video_15.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_15.jpg\n",
      "Converted video_29.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_29.jpg\n",
      "Converted video_28.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_28.jpg\n",
      "Converted video_14.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_14.jpg\n",
      "Converted video_9.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_9.jpg\n",
      "Converted video_16.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_16.jpg\n",
      "Converted video_17.jpg to grayscale and saved to /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images/video_17.jpg\n",
      "Conversion completed.\n",
      "file '/Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/yolov5/runs/detect/exp/labels/video_1.txt' Successfully updated.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "best1: [0.221296 0.475463 0.12037  0.191667]\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "All numbers 1, 2 and 3 are in the sixth position of the second file.\n",
      "Number of text files remaining in labels: 30\n",
      "Number of image files remaining in images: 30\n",
      "Resized and saved: video_1_1_1.jpg\n",
      "Resized and saved: video_16_3_0.jpg\n",
      "Resized and saved: video_8_3_0.jpg\n",
      "Resized and saved: video_30_1_1.jpg\n",
      "Resized and saved: video_20_1_1.jpg\n",
      "Resized and saved: video_15_2_1.jpg\n",
      "Resized and saved: video_29_3_0.jpg\n",
      "Resized and saved: video_1_3_0.jpg\n",
      "Resized and saved: video_8_1_1.jpg\n",
      "Resized and saved: video_23_2_1.jpg\n",
      "Resized and saved: video_16_1_1.jpg\n",
      "Resized and saved: video_20_3_0.jpg\n",
      "Resized and saved: video_30_3_0.jpg\n",
      "Resized and saved: video_2_2_1.jpg\n",
      "Resized and saved: video_29_1_1.jpg\n",
      "Resized and saved: video_17_1_1.jpg\n",
      "Resized and saved: video_9_1_1.jpg\n",
      "Resized and saved: video_22_2_1.jpg\n",
      "Resized and saved: video_21_3_0.jpg\n",
      "Resized and saved: video_3_2_1.jpg\n",
      "Resized and saved: video_28_1_1.jpg\n",
      "Resized and saved: video_9_3_0.jpg\n",
      "Resized and saved: video_17_3_0.jpg\n",
      "Resized and saved: video_14_2_1.jpg\n",
      "Resized and saved: video_21_1_1.jpg\n",
      "Resized and saved: video_28_3_0.jpg\n",
      "Resized and saved: video_15_1_1.jpg\n",
      "Resized and saved: video_30_2_1.jpg\n",
      "Resized and saved: video_20_2_1.jpg\n",
      "Resized and saved: video_2_3_0.jpg\n",
      "Resized and saved: video_1_2_1.jpg\n",
      "Resized and saved: video_23_3_0.jpg\n",
      "Resized and saved: video_15_3_0.jpg\n",
      "Resized and saved: video_29_2_1.jpg\n",
      "Resized and saved: video_2_1_1.jpg\n",
      "Resized and saved: video_16_2_1.jpg\n",
      "Resized and saved: video_23_1_1.jpg\n",
      "Resized and saved: video_8_2_1.jpg\n",
      "Resized and saved: video_14_3_0.jpg\n",
      "Resized and saved: video_28_2_1.jpg\n",
      "Resized and saved: video_3_1_1.jpg\n",
      "Resized and saved: video_22_1_1.jpg\n",
      "Resized and saved: video_9_2_1.jpg\n",
      "Resized and saved: video_17_2_1.jpg\n",
      "Resized and saved: video_21_2_1.jpg\n",
      "Resized and saved: video_14_1_1.jpg\n",
      "Resized and saved: video_3_3_0.jpg\n",
      "Resized and saved: video_22_3_0.jpg\n",
      "Resized and saved: video_5_2_1.jpg\n",
      "Resized and saved: video_27_3_0.jpg\n",
      "Resized and saved: video_24_2_1.jpg\n",
      "Resized and saved: video_11_1_1.jpg\n",
      "Resized and saved: video_18_3_0.jpg\n",
      "Resized and saved: video_6_3_0.jpg\n",
      "Resized and saved: video_27_1_1.jpg\n",
      "Resized and saved: video_12_2_1.jpg\n",
      "Resized and saved: video_11_3_0.jpg\n",
      "Resized and saved: video_6_1_1.jpg\n",
      "Resized and saved: video_18_1_1.jpg\n",
      "Resized and saved: video_13_2_1.jpg\n",
      "Resized and saved: video_26_1_1.jpg\n",
      "Resized and saved: video_10_3_0.jpg\n",
      "Resized and saved: video_19_1_1.jpg\n",
      "Resized and saved: video_7_1_1.jpg\n",
      "Resized and saved: video_4_2_1.jpg\n",
      "Resized and saved: video_26_3_0.jpg\n",
      "Resized and saved: video_10_1_1.jpg\n",
      "Resized and saved: video_25_2_1.jpg\n",
      "Resized and saved: video_7_3_0.jpg\n",
      "Resized and saved: video_19_3_0.jpg\n",
      "Resized and saved: video_11_2_1.jpg\n",
      "Resized and saved: video_24_1_1.jpg\n",
      "Resized and saved: video_5_1_1.jpg\n",
      "Resized and saved: video_12_3_0.jpg\n",
      "Resized and saved: video_24_3_0.jpg\n",
      "Resized and saved: video_18_2_1.jpg\n",
      "Resized and saved: video_6_2_1.jpg\n",
      "Resized and saved: video_5_3_0.jpg\n",
      "Resized and saved: video_12_1_1.jpg\n",
      "Resized and saved: video_27_2_1.jpg\n",
      "Resized and saved: video_25_3_0.jpg\n",
      "Resized and saved: video_7_2_1.jpg\n",
      "Resized and saved: video_19_2_1.jpg\n",
      "Resized and saved: video_4_3_0.jpg\n",
      "Resized and saved: video_26_2_1.jpg\n",
      "Resized and saved: video_13_1_1.jpg\n",
      "Resized and saved: video_25_1_1.jpg\n",
      "Resized and saved: video_10_2_1.jpg\n",
      "Resized and saved: video_4_1_1.jpg\n",
      "Resized and saved: video_13_3_0.jpg\n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data5/1.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data5/16.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data5/8.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data5/30.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data5/20.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data5/15.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data5/29.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data5/23.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data5/2.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data5/17.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data5/9.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data5/22.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data5/21.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data5/3.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data5/28.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data5/14.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data5/5.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data5/27.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data5/24.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data5/11.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data5/18.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data5/6.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data5/12.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data5/13.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data5/26.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data5/10.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data5/19.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data5/7.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data5/4.jpg  saved \n",
      "image /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset/salam/data5/25.jpg  saved \n",
      "Deleted folder: /Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/yolov5/runs/detect/exp\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 774\u001b[0m\n\u001b[1;32m    770\u001b[0m         mix_image_with_LDA(input_dir, output_base_dir, weights)\n\u001b[1;32m    773\u001b[0m \u001b[38;5;66;03m########### ran \u001b[39;00m\n\u001b[0;32m--> 774\u001b[0m ran_all(all_video_input)\n",
      "Cell \u001b[0;32mIn[1], line 710\u001b[0m, in \u001b[0;36mran_all\u001b[0;34m(all_video_input)\u001b[0m\n\u001b[1;32m    707\u001b[0m crop_video(video_path_change_name_video, save_path_change_name_video)\n\u001b[1;32m    709\u001b[0m \u001b[38;5;66;03m# 3: Run YOLOv5 detection\u001b[39;00m\n\u001b[0;32m--> 710\u001b[0m run_yolov5_detection(\n\u001b[1;32m    711\u001b[0m     video_source\u001b[38;5;241m=\u001b[39mvideo_in_video_folder,\n\u001b[1;32m    712\u001b[0m     weights_path\u001b[38;5;241m=\u001b[39myolo_weights_path,\n\u001b[1;32m    713\u001b[0m     conf_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.4\u001b[39m,\n\u001b[1;32m    714\u001b[0m     vid_stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    715\u001b[0m )\n\u001b[1;32m    717\u001b[0m \u001b[38;5;66;03m# 4: Convert video to images\u001b[39;00m\n\u001b[1;32m    718\u001b[0m video_path \u001b[38;5;241m=\u001b[39m video_in_video_folder\n",
      "Cell \u001b[0;32mIn[1], line 147\u001b[0m, in \u001b[0;36mrun_yolov5_detection\u001b[0;34m(video_source, weights_path, conf_threshold, vid_stride)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# Run the YOLOv5 detection script and capture output\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mrun(command, check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, capture_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCommand Output:\u001b[39m\u001b[38;5;124m\"\u001b[39m, result\u001b[38;5;241m.\u001b[39mstdout)\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCommand Error:\u001b[39m\u001b[38;5;124m\"\u001b[39m, result\u001b[38;5;241m.\u001b[39mstderr)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/subprocess.py:550\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 550\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mcommunicate(\u001b[38;5;28minput\u001b[39m, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    552\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/subprocess.py:1209\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1206\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1209\u001b[0m     stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_communicate(\u001b[38;5;28minput\u001b[39m, endtime, timeout)\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1211\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m     \u001b[38;5;66;03m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/subprocess.py:2108\u001b[0m, in \u001b[0;36mPopen._communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   2101\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timeout(endtime, orig_timeout,\n\u001b[1;32m   2102\u001b[0m                         stdout, stderr,\n\u001b[1;32m   2103\u001b[0m                         skip_check_and_raise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   2104\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(  \u001b[38;5;66;03m# Impossible :)\u001b[39;00m\n\u001b[1;32m   2105\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_check_timeout(..., skip_check_and_raise=True) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2106\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfailed to raise TimeoutExpired.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 2108\u001b[0m ready \u001b[38;5;241m=\u001b[39m selector\u001b[38;5;241m.\u001b[39mselect(timeout)\n\u001b[1;32m   2109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timeout(endtime, orig_timeout, stdout, stderr)\n\u001b[1;32m   2111\u001b[0m \u001b[38;5;66;03m# XXX Rewrite these to use non-blocking I/O on the file\u001b[39;00m\n\u001b[1;32m   2112\u001b[0m \u001b[38;5;66;03m# objects; they are no longer using C stdio!\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selector\u001b[38;5;241m.\u001b[39mpoll(timeout)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from IPython.display import Image\n",
    "from random import choice\n",
    "import shutil\n",
    "import glob\n",
    "import numpy as np\n",
    "import shutil\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "import subprocess\n",
    "\n",
    "\n",
    "###path\n",
    "all_video_input = \"/Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/all_video\"\n",
    "one_video_input = \"/Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/all_video/bebakhshid1.mp4\"\n",
    "video_in_video_folder = \"/Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video/video.mp4\"\n",
    "\n",
    "video_folder =\"/Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/1_video\"\n",
    "convert_video_to_images_folder = \"/Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/2_convert_video_to_images\"\n",
    "square_images_folder = \"/Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/3_square_images\"\n",
    "resized_images_folder = \"/Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/4_resized_images\"\n",
    "dataset_end = \"/Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/dataset\"\n",
    "\n",
    "yolo_folder = '/Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/yolov5'\n",
    "detect_folder = \"/Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/yolov5/runs/detect\"\n",
    "labels_folder = \"/Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/yolov5/runs/detect/exp/labels\"\n",
    "yolo_weights_path = \"/Users/yayhaeslami/Desktop/my_workspace/sign_language/preparing_dataset/yolov5/runs/train/weights/best.pt\"\n",
    "\n",
    "#name class\n",
    "name_class = \"salam\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# مسیرهای مورد نظر\n",
    "paths = [\n",
    "    video_folder,\n",
    "    convert_video_to_images_folder,\n",
    "    square_images_folder,\n",
    "    resized_images_folder,\n",
    "    yolo_weights_path,\n",
    "    dataset_end\n",
    "]\n",
    "\n",
    "# ایجاد فولدرها\n",
    "for path in paths:\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "        print(f\"Folder created: {path}\")\n",
    "    except FileExistsError:\n",
    "        print(f\"Folder already exists: {path}\")\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "### 1_ Deleted all files\n",
    "\n",
    "\n",
    "\n",
    "def delete_files_and_folders(pathsـdelete_files):\n",
    "    for folder_path in pathsـdelete_files:\n",
    "        items = glob.glob(os.path.join(folder_path, \"*\"))\n",
    "\n",
    "        for item in items:\n",
    "            try:\n",
    "                if os.path.isfile(item) or os.path.islink(item):\n",
    "                    os.remove(item)  \n",
    "            \n",
    "                elif os.path.isdir(item):\n",
    "                    shutil.rmtree(item)  \n",
    "                    print(f\"Deleted folder: {item}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error deleting {item}: {e}\")\n",
    "\n",
    "\n",
    "### 2_ cut up and down video and change name video\n",
    "\n",
    "def crop_video(video_path_change_name_video, save_path_change_name_video):\n",
    "\n",
    "    video_capture = cv2.VideoCapture(video_path_change_name_video)\n",
    "\n",
    "    width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    min_size = min(width, height)\n",
    "    start_x = (width - min_size) // 2\n",
    "    start_y = (height - min_size) // 2\n",
    "\n",
    "    crop_region = (start_x, start_y, min_size, min_size)\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v') \n",
    "    video_writer = cv2.VideoWriter(save_path_change_name_video, fourcc, 30, (min_size, min_size))\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        cropped_frame = frame[start_y:start_y+min_size, start_x:start_x+min_size]\n",
    "\n",
    "\n",
    "        video_writer.write(cropped_frame)\n",
    "\n",
    "\n",
    "    video_capture.release()\n",
    "    video_writer.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 3_ ran yolo model\n",
    "\n",
    "def run_yolov5_detection(video_source, weights_path, conf_threshold=0.4, vid_stride=1):\n",
    "    \"\"\"\n",
    "    Runs YOLOv5 object detection on a video source.\n",
    "\n",
    "    Parameters:\n",
    "        video_source (str): Path to the video file or directory containing images.\n",
    "        weights_path (str): Path to the YOLOv5 weights file.\n",
    "        conf_threshold (float, optional): Confidence threshold for detection. Defaults to 0.4.\n",
    "        vid_stride (int, optional): Frame stride for video processing. Defaults to 1.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(yolo_folder):\n",
    "        raise FileNotFoundError(f\"Directory {yolo_folder} does not exist\")\n",
    "    \n",
    "    # Construct the command with absolute paths\n",
    "    detect_script = os.path.join(yolo_folder, 'detect.py')\n",
    "    command = [\n",
    "        'python', detect_script,\n",
    "        '--source', video_source,\n",
    "        '--weights', weights_path,\n",
    "        '--save-txt',\n",
    "        '--vid-stride', str(vid_stride),\n",
    "        '--conf-thres', str(conf_threshold)\n",
    "    ]\n",
    "    \n",
    "    # Run the YOLOv5 detection script and capture output\n",
    "    try:\n",
    "        result = subprocess.run(command, check=True, capture_output=True, text=True)\n",
    "        print(\"Command Output:\", result.stdout)\n",
    "        print(\"Command Error:\", result.stderr)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Error executing command:\")\n",
    "        print(e.output)\n",
    "        print(e.stderr)\n",
    "        raise\n",
    "\n",
    "\n",
    "\n",
    "###4_ extract frames from video\n",
    "def convert_video_to_images(video_path, output_folder):\n",
    "    base_name = os.path.basename(video_path).split('.')[0]\n",
    "    \n",
    "    vidcap = cv2.VideoCapture(video_path)\n",
    "    success, image = vidcap.read()\n",
    "    count = 0\n",
    "    frame_interval = 1 \n",
    "\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    while success:\n",
    "        if count % frame_interval == 0:\n",
    "            image_path = os.path.join(output_folder, f\"{base_name}_{count // frame_interval + 1}.jpg\")\n",
    "            cv2.imwrite(image_path, image) \n",
    "        success, image = vidcap.read()\n",
    "        count += 1\n",
    "\n",
    "    print(f\"{count // frame_interval} frames extracted.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###5_ Convert photos to black and white\n",
    "\n",
    "def convert_photos_to_grayscale(input_folder):\n",
    "    \"\"\"\n",
    "    Converts photos in the input folder to grayscale and saves them in the output folder.\n",
    "\n",
    "    Args:\n",
    "        input_folder (str): The path to the folder containing the images.\n",
    "        output_folder (str): The path to the folder where the grayscale images will be saved.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(input_folder):\n",
    "        os.makedirs(input_folder)\n",
    "\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            input_path = os.path.join(input_folder, filename)\n",
    "            \n",
    "            img = cv2.imread(input_path)\n",
    "            \n",
    "            gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "\n",
    "            output_path = os.path.join(input_folder, filename)\n",
    "\n",
    "            cv2.imwrite(output_path, gray_img)\n",
    "            \n",
    "            print(f\"Converted {filename} to grayscale and saved to {output_path}\")\n",
    "\n",
    "    print(\"Conversion completed.\")\n",
    "\n",
    "\n",
    "### 6_ add 1,2,3 to ferst file .txt with Right hand and left hand detection\n",
    "\n",
    "def add_number_to_ferst_file(folder_path_labels):\n",
    "    file_pattern = os.path.join(folder_path_labels , \"*_1.txt\")\n",
    "    files = glob.glob(file_pattern)\n",
    "\n",
    "    if files:\n",
    "        file_path = files[0]\n",
    "        with open(file_path, 'r+') as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        hands = []\n",
    "        others = []\n",
    "        for line in lines:\n",
    "            if line.startswith(\"1\"):\n",
    "                hands.append(line.strip())\n",
    "            else:\n",
    "                others.append(line.strip())\n",
    "        \n",
    "        hands_sorted = sorted(hands, key=lambda x: float(x.split()[1]))\n",
    "        \n",
    "        right_hand = \"\"\n",
    "        left_hand = \"\"\n",
    "\n",
    "        if len(hands_sorted) >= 1:\n",
    "            right_hand = hands_sorted[0] + \" 1\"\n",
    "        if len(hands_sorted) >= 2:\n",
    "            left_hand = hands_sorted[1] + \" 2\"\n",
    "\n",
    "        others = [coord + \" 3\" for coord in others]\n",
    "\n",
    "        result = []\n",
    "        if right_hand:\n",
    "            result.append(right_hand)\n",
    "        if left_hand:\n",
    "            result.append(left_hand)\n",
    "        result.extend(others)\n",
    "\n",
    "        with open(file_path, 'w') as f:\n",
    "            for line in result:\n",
    "                f.write(line + \"\\n\")\n",
    "\n",
    "        print(f\"file '{file_path}' Successfully updated.\")\n",
    "    else:\n",
    "        print(\"No file with extension _1.txt was found in the desired path.\")\n",
    "\n",
    "\n",
    "\n",
    "######7_ Prepare text file for cut image\n",
    "\n",
    "def Prepare_text_file_for_cut_image(directory_path_labels_folder):\n",
    "\n",
    "    def extract_first_digit_after_decimal(line):\n",
    "        parts = line.strip().split()\n",
    "        first_digits_after_decimal = []\n",
    "        for part in parts[1:5]:\n",
    "            if '.' in part:\n",
    "                fraction_part = part.split('.')[1]\n",
    "                if len(fraction_part) > 0:\n",
    "                    first_digits_after_decimal.append(int(fraction_part[0]))\n",
    "                else:\n",
    "                    first_digits_after_decimal.append(0)\n",
    "            else:\n",
    "                first_digits_after_decimal.append(0)\n",
    "        return first_digits_after_decimal\n",
    "\n",
    "    def extract_second_digit_after_decimal(line):\n",
    "        parts = line.strip().split()\n",
    "        second_digits_after_decimal = []\n",
    "        for part in parts[1:5]:\n",
    "            if '.' in part:\n",
    "                fraction_part = part.split('.')[1]\n",
    "                if len(fraction_part) > 1:\n",
    "                    second_digits_after_decimal.append(int(fraction_part[1]))\n",
    "                else:\n",
    "                    second_digits_after_decimal.append(0)\n",
    "            else:\n",
    "                second_digits_after_decimal.append(0)\n",
    "        return second_digits_after_decimal\n",
    "\n",
    "    def count_matching_digits(list1, list2):\n",
    "        return sum(1 for a, b in zip(list1, list2) if a == b)\n",
    "\n",
    "    def read_file(file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "        return [list(map(float, line.strip().split())) for line in lines]\n",
    "\n",
    "    def write_file(file_path, lines):\n",
    "        with open(file_path, 'w') as file:\n",
    "            for line in lines:\n",
    "                formatted_line = ' '.join([f\"{int(num)}\" if num.is_integer() else f\"{num}\" for num in line])\n",
    "                file.write(formatted_line + '\\n')\n",
    "\n",
    "    def find_lines_with_sixth_element(lines, value):\n",
    "        return [line for line in lines if len(line) > 5 and line[5] == value]\n",
    "\n",
    "    def predict_next_coordinate(prev1, prev2):\n",
    "        diff = np.array(prev2) - np.array(prev1)\n",
    "        predicted = np.array(prev2) + diff\n",
    "        return predicted\n",
    "\n",
    "    def select_best_coordinate(predicted, candidates):\n",
    "        best_candidate = None\n",
    "        best_distance = float('inf')\n",
    "        \n",
    "        for candidate in candidates:\n",
    "            candidate = np.array(candidate)\n",
    "            distance = np.linalg.norm(candidate - predicted)\n",
    "            \n",
    "            if distance < best_distance:\n",
    "                best_distance = distance\n",
    "                best_candidate = candidate\n",
    "        \n",
    "        return best_candidate\n",
    "\n",
    "    def process_files(file_path1, file_path2):\n",
    "        with open(file_path1, 'r') as file1, open(file_path2, 'r') as file2:\n",
    "            lines1 = file1.readlines()\n",
    "            lines2 = file2.readlines()\n",
    "\n",
    "        first_digits_list1 = [extract_first_digit_after_decimal(line) for line in lines1]\n",
    "        second_digits_list1 = [extract_second_digit_after_decimal(line) for line in lines1]\n",
    "\n",
    "        with open(file_path2, 'w') as file2:\n",
    "            for line2 in lines2:\n",
    "                first_digits2 = extract_first_digit_after_decimal(line2)\n",
    "                second_digits2 = extract_second_digit_after_decimal(line2)\n",
    "                matched_indices = []\n",
    "                matched = False\n",
    "\n",
    "                for i, first_digits1 in enumerate(first_digits_list1):\n",
    "                    if first_digits1 == first_digits2:\n",
    "                        matched_indices.append(i)\n",
    "\n",
    "                if len(matched_indices) == 1:\n",
    "                    parts = line2.strip().split()\n",
    "                    matched_line_parts = lines1[matched_indices[0]].strip().split()\n",
    "                    if len(matched_line_parts) > 5:\n",
    "                        parts.append(matched_line_parts[5])\n",
    "                    else:\n",
    "                        parts.append('')  # Leave the 6th number empty\n",
    "                    file2.write(' '.join(parts) + '\\n')\n",
    "                    matched = True\n",
    "                elif len(matched_indices) > 1:\n",
    "                    for i in matched_indices:\n",
    "                        if second_digits_list1[i] == second_digits2:\n",
    "                            parts = line2.strip().split()\n",
    "                            matched_line_parts = lines1[i].strip().split()\n",
    "                            if len(matched_line_parts) > 5:\n",
    "                                parts.append(matched_line_parts[5])\n",
    "                            else:\n",
    "                                parts.append('')  # Leave the 6th number empty\n",
    "                            file2.write(' '.join(parts) + '\\n')\n",
    "                            matched = True\n",
    "                            break\n",
    "\n",
    "                if not matched:\n",
    "                    for i, first_digits1 in enumerate(first_digits_list1):\n",
    "                        if count_matching_digits(first_digits1, first_digits2) >= 3:\n",
    "                            parts = line2.strip().split()\n",
    "                            matched_line_parts = lines1[i].strip().split()\n",
    "                            if len(matched_line_parts) > 5:\n",
    "                                parts.append(matched_line_parts[5])\n",
    "                            else:\n",
    "                                parts.append('')  # Leave the 6th number empty\n",
    "                            file2.write(' '.join(parts) + '\\n')\n",
    "                            matched = True\n",
    "                            break\n",
    "\n",
    "                if not matched:\n",
    "                    parts = line2.strip().split()\n",
    "                    parts.append('')  # Leave the 6th number empty\n",
    "                    file2.write(' '.join(parts) + '\\n')\n",
    "                    \n",
    "        file1_lines = read_file(file_path1)\n",
    "        file2_lines = read_file(file_path2)\n",
    "        \n",
    "        missing_values = [val for val in [1, 2, 3] if val not in [line[5] for line in file2_lines if len(line) > 5]]\n",
    "        \n",
    "        if missing_values:\n",
    "            missing_value = missing_values[0]  \n",
    "            \n",
    "            \n",
    "            file1_lines_with_missing = find_lines_with_sixth_element(file1_lines, missing_value)\n",
    "            \n",
    "            if file1_lines_with_missing:\n",
    "                \n",
    "                prev1 = file1_lines_with_missing[0][1:5]  \n",
    "                prev2 = file1_lines_with_missing[1][1:5] if len(file1_lines_with_missing) > 1 else prev1 \n",
    "                \n",
    "            \n",
    "                candidates = [line for line in file2_lines if len(line) <= 5 or (line[5] != 1 and line[5] != 2 and line[5] != 3)]\n",
    "                candidate_coords = [line[1:5] for line in candidates]\n",
    "                \n",
    "                if candidate_coords:\n",
    "                    \n",
    "                    predicted = predict_next_coordinate(prev1, prev2)\n",
    "                    \n",
    "                    \n",
    "                    best_coordinate = select_best_coordinate(predicted, candidate_coords)\n",
    "                    \n",
    "                    print(f\"best{missing_value}:\", best_coordinate)\n",
    "                    \n",
    "                    \n",
    "                    for line in candidates:\n",
    "                        if line[1:5] == best_coordinate.tolist():\n",
    "                            line.append(float(missing_value))\n",
    "                    \n",
    "                    \n",
    "                    write_file(file_path2, file2_lines)\n",
    "                else:\n",
    "                    print(\"There is no line without the sixth number or with the sixth number 1, 2, 3 in the second file.\")\n",
    "            else:\n",
    "                print(f\"No lines with numbers{missing_value} It is not present in the sixth position in the first file.\")\n",
    "        else:\n",
    "            print(\"All numbers 1, 2 and 3 are in the sixth position of the second file.\")\n",
    "\n",
    "    def process_files_in_directory(directory):\n",
    "        file_names = os.listdir(directory)\n",
    "        file_names = [f for f in file_names if f.endswith('.txt')]\n",
    "        file_names.sort(key=lambda x: int(x.split('_')[1].split('.')[0]))\n",
    "\n",
    "        for i in range(len(file_names) - 1):\n",
    "            file_path1 = os.path.join(directory, file_names[i])\n",
    "            file_path2 = os.path.join(directory, file_names[i + 1])\n",
    "            process_files(file_path1, file_path2)\n",
    "\n",
    "    directory_path = directory_path_labels_folder\n",
    "    process_files_in_directory(directory_path)\n",
    "\n",
    "\n",
    "\n",
    "###8_ Deleted lines in files that haven't six number\n",
    "def Deleted_lines_in_files_that_haven_not_six_number(directory_path_labels_folder):\n",
    "\n",
    "    def read_file(file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "        return lines\n",
    "\n",
    "    def write_file(file_path, lines):\n",
    "        with open(file_path, 'w') as file:\n",
    "            for line in lines:\n",
    "                file.write(line)\n",
    "\n",
    "    def remove_lines_without_sixth_number(file_path):\n",
    "        lines = read_file(file_path)\n",
    "        filtered_lines = [line for line in lines if len(line.strip().split()) > 5]\n",
    "        write_file(file_path, filtered_lines)\n",
    "\n",
    "    def process_files_in_directory(directory):\n",
    "        file_names = os.listdir(directory)\n",
    "        file_names = [f for f in file_names if f.endswith('.txt')]\n",
    "\n",
    "        for file_name in file_names:\n",
    "            file_path = os.path.join(directory, file_name)\n",
    "            remove_lines_without_sixth_number(file_path)\n",
    "\n",
    "    directory_path = directory_path_labels_folder\n",
    "    process_files_in_directory(directory_path)\n",
    "\n",
    "\n",
    "\n",
    "###9_ Deleted file and image to 30\n",
    "def Deleted_file_and_image(labels_directory, images_directory):\n",
    "    label_files_before = set([f for f in os.listdir(labels_directory) if f.endswith('.txt')])\n",
    "\n",
    "    def get_file_number(filename):\n",
    "        return int(filename.split('_')[1].split('.')[0])\n",
    "\n",
    "    label_files_before = sorted(label_files_before, key=get_file_number)\n",
    "\n",
    "    def reduce_files_uniformly(files, target_count):\n",
    "        total_files = len(files)\n",
    "        if total_files <= target_count:\n",
    "            return files\n",
    "        \n",
    "        step = total_files / (total_files - target_count)\n",
    "        indices_to_remove = [int(i * step) for i in range(total_files - target_count)]\n",
    "        \n",
    "        for index in sorted(indices_to_remove, reverse=True):\n",
    "            os.remove(os.path.join(labels_directory, files[index]))\n",
    "        \n",
    "        remaining_files = [f for f in os.listdir(labels_directory) if f.endswith('.txt')]\n",
    "        remaining_files.sort(key=get_file_number)\n",
    "        return remaining_files\n",
    "\n",
    "    remaining_label_files = reduce_files_uniformly(label_files_before, 30)\n",
    "\n",
    "    deleted_label_files = set(label_files_before) - set(remaining_label_files)\n",
    "\n",
    "    for label_file in deleted_label_files:\n",
    "        image_file = label_file.replace('.txt', '.jpg')\n",
    "        image_path = os.path.join(images_directory, image_file)\n",
    "        if os.path.exists(image_path):\n",
    "            os.remove(image_path)\n",
    "\n",
    "    remaining_image_files = [f for f in os.listdir(images_directory) if f.endswith('.jpg')]\n",
    "    print(f\"Number of text files remaining in labels: {len(remaining_label_files)}\")\n",
    "    print(f\"Number of image files remaining in images: {len(remaining_image_files)}\")\n",
    "\n",
    "    def rename_files(directory, extension):\n",
    "        files = [f for f in os.listdir(directory) if f.endswith(extension)]\n",
    "        \n",
    "        files.sort(key=lambda f: int(re.search(r'_(\\d+)', f).group(1)))\n",
    "        \n",
    "        for i, filename in enumerate(files, start=1):\n",
    "            new_filename = re.sub(r'_\\d+', f'_{i}', filename)\n",
    "            os.rename(os.path.join(directory, filename), os.path.join(directory, new_filename))\n",
    "\n",
    "    rename_files(labels_directory, '.txt')\n",
    "\n",
    "    rename_files(images_directory, '.jpg')\n",
    "    rename_files(images_directory, '.png')\n",
    "    rename_files(images_directory, '.jpeg')\n",
    "\n",
    "\n",
    "###10_ cut image by text file\n",
    "\n",
    "def cut_image_by_text_file(labels_folder_path, images_folder_path, save_folder):\n",
    "    def convert_to_square(file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "            modified_lines = []\n",
    "            for line in lines:\n",
    "                label, x_center, y_center, width, height, additional_number = map(float, line.split())\n",
    "                \n",
    "                max_size = max(width, height)\n",
    "                \n",
    "                x1 = max(x_center - max_size / 2, 0)\n",
    "                y1 = max(y_center - max_size / 2, 0)\n",
    "                x2 = x1 + abs(max_size)\n",
    "                y2 = y1 + abs(max_size)\n",
    "                \n",
    "                modified_lines.append(f\"{int(label)} {x1} {y1} {x2} {y2} {int(additional_number)}\\n\")\n",
    "            \n",
    "            return modified_lines\n",
    "\n",
    "    def crop_and_save_squares(image_path, coordinates, save_folder):\n",
    "        image = cv2.imread(image_path)\n",
    "        image_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "\n",
    "        for i, (label, (x1, y1), (x2, y2), additional_number) in enumerate(coordinates):\n",
    "            x1_pixel = int(x1 * image.shape[1])\n",
    "            y1_pixel = int(y1 * image.shape[0])\n",
    "            x2_pixel = int(x2 * image.shape[1])\n",
    "            y2_pixel = int(y2 * image.shape[0])\n",
    "\n",
    "            cropped_image = image[y1_pixel:y2_pixel, x1_pixel:x2_pixel]\n",
    "\n",
    "            cropped_save_path = os.path.join(save_folder, f\"{image_name}_{additional_number}_{label}.jpg\")\n",
    "            cv2.imwrite(cropped_save_path, cropped_image)\n",
    "\n",
    "\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "    file_list = os.listdir(labels_folder_path)\n",
    "\n",
    "    for file_name in file_list:\n",
    "        if file_name.endswith(\".txt\"): \n",
    "            text_file_path = os.path.join(labels_folder_path, file_name)\n",
    "            \n",
    "            modified_lines = convert_to_square(text_file_path)\n",
    "            \n",
    "            coordinates = []\n",
    "            for line in modified_lines:\n",
    "                label, x1, y1, x2, y2, additional_number = map(float, line.split())\n",
    "                coordinates.append((int(label), (x1, y1), (x2, y2), int(additional_number)))\n",
    "            \n",
    "            image_file_name = os.path.splitext(file_name)[0] + \".jpg\"\n",
    "            image_path = os.path.join(images_folder_path, image_file_name)\n",
    "            if os.path.exists(image_path):\n",
    "\n",
    "                crop_and_save_squares(image_path, coordinates, save_folder)\n",
    "            else:\n",
    "                print(f\"{file_name} not found.\")\n",
    "\n",
    "\n",
    "###11_ change Dimensions to 128 * 128\n",
    "\n",
    "def resize_images(input_folder_square_images_Dimensions, output_folder_resized_images_Dimensions, size):\n",
    "    if not os.path.exists(output_folder_resized_images_Dimensions):\n",
    "        os.makedirs(output_folder_resized_images_Dimensions)\n",
    "\n",
    "    for filename in os.listdir(input_folder_square_images_Dimensions):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
    "            img_path = os.path.join(input_folder_square_images_Dimensions, filename)\n",
    "            image = cv2.imread(img_path)\n",
    "            if image is not None:\n",
    "                resized_image = cv2.resize(image, size)\n",
    "                \n",
    "                output_path = os.path.join(output_folder_resized_images_Dimensions, filename)\n",
    "                \n",
    "                cv2.imwrite(output_path, resized_image)\n",
    "                print(f\"Resized and saved: {filename}\")\n",
    "            else:\n",
    "                print(f\"Failed to read: {filename}\")\n",
    "\n",
    "\n",
    "###12_ mix 3 image to one with LDA\n",
    "\n",
    "def mix_image_with_LDA(input_dir, output_base_dir, weights):\n",
    "    image_groups = defaultdict(list)\n",
    "\n",
    "    pattern = re.compile(r'^(.*?)_(\\d+)_(\\d+)')\n",
    "\n",
    "    for filename in os.listdir(input_dir):\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            #class_name = match.group(1)\n",
    "            class_name = name_class\n",
    "            group_id = match.group(2)\n",
    "            weight_id = int(match.group(3))\n",
    "            image_groups[class_name].append((os.path.join(input_dir, filename), group_id, weight_id))\n",
    "\n",
    "    def load_image(image_path):\n",
    "        with Image.open(image_path) as img:\n",
    "            return np.array(img)\n",
    "\n",
    "    def get_next_data_folder(base_dir):\n",
    "        existing_folders = [d for d in os.listdir(base_dir) if d.startswith('data')]\n",
    "        if not existing_folders:\n",
    "            return os.path.join(base_dir, 'data1')\n",
    "        existing_numbers = [int(re.search(r'data(\\d+)', d).group(1)) for d in existing_folders if re.search(r'data(\\d+)', d)]\n",
    "        next_number = max(existing_numbers) + 1\n",
    "        return os.path.join(base_dir, f'data{next_number}')\n",
    "\n",
    "\n",
    "    for class_name, image_paths_groups_weights in image_groups.items():\n",
    "\n",
    "        class_dir = os.path.join(output_base_dir, class_name)\n",
    "        if not os.path.exists(class_dir):\n",
    "            os.makedirs(class_dir)\n",
    "\n",
    "\n",
    "        data_dir = get_next_data_folder(class_dir)\n",
    "        os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "        group_images = defaultdict(list)\n",
    "        \n",
    "        for image_path, group_id, weight_id in image_paths_groups_weights:\n",
    "\n",
    "            image = load_image(image_path)\n",
    "\n",
    "\n",
    "            weight = weights.get(weight_id, 1) \n",
    "\n",
    "\n",
    "            group_images[group_id].append((image, weight))\n",
    "\n",
    "        for group_id, images_weights in group_images.items():\n",
    "\n",
    "            combined_image = np.zeros_like(images_weights[0][0], dtype=np.float64)\n",
    "            total_weight = 0\n",
    "\n",
    "            for image, weight in images_weights:\n",
    "                combined_image += image * weight\n",
    "                total_weight += weight\n",
    "\n",
    "            if total_weight > 0:\n",
    "                combined_image /= total_weight\n",
    "\n",
    "        \n",
    "            output_path = os.path.join(data_dir, f\"{group_id}.jpg\")\n",
    "            Image.fromarray(combined_image.astype(np.uint8)).save(output_path)\n",
    "\n",
    "            print(f\"image {output_path}  saved \")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "def ran_all(all_video_input):\n",
    "    for video_path in os.listdir(all_video_input):\n",
    "        video_in_folder = os.path.join(all_video_input, video_path)\n",
    "\n",
    "        # 1: Delete files and folders\n",
    "        paths_delete_files = [ \n",
    "            video_folder,\n",
    "            convert_video_to_images_folder,\n",
    "            square_images_folder,\n",
    "            resized_images_folder,\n",
    "            detect_folder\n",
    "        ]\n",
    "\n",
    "        delete_files_and_folders(paths_delete_files)\n",
    "\n",
    "        # 2: Crop video\n",
    "        video_path_change_name_video = video_in_folder\n",
    "        save_path_change_name_video = video_in_video_folder\n",
    "\n",
    "        crop_video(video_path_change_name_video, save_path_change_name_video)\n",
    "\n",
    "        # 3: Run YOLOv5 detection\n",
    "        run_yolov5_detection(\n",
    "            video_source=video_in_video_folder,\n",
    "            weights_path=yolo_weights_path,\n",
    "            conf_threshold=0.4,\n",
    "            vid_stride=1\n",
    "        )\n",
    "\n",
    "        # 4: Convert video to images\n",
    "        video_path = video_in_video_folder\n",
    "        output_folder = convert_video_to_images_folder\n",
    "\n",
    "        convert_video_to_images(video_path, output_folder)\n",
    "\n",
    "        # 5: Convert photos to grayscale\n",
    "        input_folder = convert_video_to_images_folder\n",
    "\n",
    "        convert_photos_to_grayscale(input_folder)\n",
    "\n",
    "        # 6: Add number to the first file\n",
    "        folder_path_labels = labels_folder\n",
    "\n",
    "        add_number_to_ferst_file(folder_path_labels)\n",
    "\n",
    "        # 7: Prepare text file for cutting images\n",
    "        directory_path_labels_folder = labels_folder\n",
    "\n",
    "        Prepare_text_file_for_cut_image(directory_path_labels_folder)\n",
    "\n",
    "        # 8: Delete lines in files that haven't six numbers\n",
    "        Deleted_lines_in_files_that_haven_not_six_number(directory_path_labels_folder)\n",
    "\n",
    "        # 9: Delete file and image\n",
    "        labels_directory = labels_folder\n",
    "        images_directory = convert_video_to_images_folder\n",
    "\n",
    "        Deleted_file_and_image(labels_directory, images_directory)\n",
    "\n",
    "        # 10: Cut image by text file\n",
    "        labels_folder_path = labels_folder\n",
    "        images_folder_path = convert_video_to_images_folder\n",
    "        save_folder = square_images_folder\n",
    "\n",
    "        cut_image_by_text_file(labels_folder_path, images_folder_path, save_folder)\n",
    "\n",
    "        # 11: Resize images\n",
    "        input_folder_square_images_Dimensions = square_images_folder\n",
    "        output_folder_resized_images_Dimensions = resized_images_folder\n",
    "        size = (128, 128)\n",
    "\n",
    "        resize_images(input_folder_square_images_Dimensions, output_folder_resized_images_Dimensions, size)\n",
    "\n",
    "        # 12: Mix image with LDA\n",
    "        input_dir = resized_images_folder\n",
    "        output_base_dir = dataset_end\n",
    "        weights = {\n",
    "            1: 0.5,\n",
    "            2: 0.5,  \n",
    "            3: 0.5   \n",
    "        }\n",
    "\n",
    "        mix_image_with_LDA(input_dir, output_base_dir, weights)\n",
    "\n",
    "\n",
    "########### ran \n",
    "ran_all(all_video_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
