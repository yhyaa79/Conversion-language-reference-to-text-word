{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CNN-RNN model\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, LSTM, TimeDistributed, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "image_size = (125, 128)\n",
    "\n",
    "# name classes\n",
    "classes = [\"your classes\"]\n",
    "num_classes = len(classes)\n",
    "frames_per_sequence = 30\n",
    "\n",
    "\n",
    "def load_data(base_path):\n",
    "    X, y = [], []\n",
    "    for class_index, class_name in enumerate(classes):\n",
    "        class_path = os.path.join(base_path, class_name)\n",
    "        for data_folder in os.listdir(class_path):\n",
    "            data_path = os.path.join(class_path, data_folder)\n",
    "            if os.path.isdir(data_path):\n",
    "                frames = []\n",
    "                for frame_file in sorted(os.listdir(data_path)):\n",
    "                    if frame_file.endswith('.jpg'):\n",
    "                        frame_path = os.path.join(data_path, frame_file)\n",
    "                        img = load_img(frame_path, target_size=image_size, color_mode='grayscale')\n",
    "                        img_array = img_to_array(img)\n",
    "                        frames.append(img_array)\n",
    "                if len(frames) == frames_per_sequence:\n",
    "                    X.append(np.array(frames))\n",
    "                    y.append(class_index)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "\n",
    "base_path = 'path your dataset' \n",
    "X, y = load_data(base_path)\n",
    "\n",
    "X = X / 255.0\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "input_shape = (frames_per_sequence, *image_size, 1)\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "cnn_model = TimeDistributed(Conv2D(32, (3, 3), activation='relu'))(input_layer)\n",
    "cnn_model = TimeDistributed(MaxPooling2D((2, 2)))(cnn_model)\n",
    "cnn_model = TimeDistributed(Conv2D(64, (3, 3), activation='relu'))(cnn_model)\n",
    "cnn_model = TimeDistributed(MaxPooling2D((2, 2)))(cnn_model)\n",
    "cnn_model = TimeDistributed(Conv2D(128, (3, 3), activation='relu'))(cnn_model)\n",
    "cnn_model = TimeDistributed(MaxPooling2D((2, 2)))(cnn_model)\n",
    "cnn_model = TimeDistributed(Flatten())(cnn_model)\n",
    "\n",
    "rnn_model = LSTM(128, return_sequences=False)(cnn_model)\n",
    "rnn_model = Dropout(0.5)(rnn_model)\n",
    "output_layer = Dense(num_classes, activation='softmax')(rnn_model)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "\n",
    "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, batch_size=8)\n",
    "\n",
    "\n",
    "model.save('cnn_rnn_model.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3D-CNN model\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv3D, MaxPooling3D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "image_size = (125, 128)\n",
    "frames_per_sequence = 30\n",
    "# name classes\n",
    "classes = [\"your classes\"]\n",
    "num_classes = len(classes)\n",
    "\n",
    "def load_data(base_path):\n",
    "    X, y = [], []\n",
    "    for class_index, class_name in enumerate(classes):\n",
    "        class_path = os.path.join(base_path, class_name)\n",
    "        for data_folder in os.listdir(class_path):\n",
    "            data_path = os.path.join(class_path, data_folder)\n",
    "            if os.path.isdir(data_path):\n",
    "                frames = []\n",
    "                for frame_file in sorted(os.listdir(data_path)):\n",
    "                    if frame_file.endswith('.jpg'):\n",
    "                        frame_path = os.path.join(data_path, frame_file)\n",
    "                        img = load_img(frame_path, target_size=image_size, color_mode='grayscale')\n",
    "                        img_array = img_to_array(img)\n",
    "                        frames.append(img_array)\n",
    "                if len(frames) == frames_per_sequence:\n",
    "                    X.append(np.array(frames))\n",
    "                    y.append(class_index)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "\n",
    "base_path = 'path your dataset' \n",
    "X, y = load_data(base_path)\n",
    "\n",
    "X = X.astype('float32') / 255.0\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "input_shape = (frames_per_sequence, *image_size, 1)\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "model = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(input_layer)\n",
    "model = MaxPooling3D((1, 2, 2))(model)\n",
    "model = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(model)\n",
    "model = MaxPooling3D((2, 2, 2))(model)\n",
    "model = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(model)\n",
    "model = MaxPooling3D((2, 2, 2))(model)\n",
    "model = Flatten()(model)\n",
    "model = Dense(128, activation='relu')(model)\n",
    "model = Dropout(0.5)(model)\n",
    "output_layer = Dense(num_classes, activation='softmax')(model)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, batch_size=8)\n",
    "\n",
    "model.save('3d_cnn_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CNN-RNN Model with LLM for Multifunctional Issues\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, LSTM, TimeDistributed, Dropout, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import TFBertModel, BertTokenizer\n",
    "\n",
    "\n",
    "image_size = (125, 128)\n",
    "frames_per_sequence = 30\n",
    "# name classes\n",
    "classes = [\"your classes\"]\n",
    "num_classes = len(classes)\n",
    "\n",
    "def load_data(base_path):\n",
    "    X, y, texts = [], [], []\n",
    "    for class_index, class_name in enumerate(classes):\n",
    "        class_path = os.path.join(base_path, class_name)\n",
    "        for data_folder in os.listdir(class_path):\n",
    "            data_path = os.path.join(class_path, data_folder)\n",
    "            if os.path.isdir(data_path):\n",
    "                frames = []\n",
    "                text_path = os.path.join(data_path, \"text.txt\")  \n",
    "                with open(text_path, 'r', encoding='utf-8') as f:\n",
    "                    text = f.read().strip()\n",
    "                for frame_file in sorted(os.listdir(data_path)):\n",
    "                    if frame_file.endswith('.jpg'):\n",
    "                        frame_path = os.path.join(data_path, frame_file)\n",
    "                        img = load_img(frame_path, target_size=image_size, color_mode='grayscale')\n",
    "                        img_array = img_to_array(img)\n",
    "                        frames.append(img_array)\n",
    "                if len(frames) == frames_per_sequence:\n",
    "                    X.append(np.array(frames))\n",
    "                    y.append(class_index)\n",
    "                    texts.append(text)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y, texts\n",
    "\n",
    "base_path = 'path your dataset' \n",
    "X, y, texts = load_data(base_path)\n",
    "\n",
    "X = X.astype('float32') / 255.0\n",
    "\n",
    "X_train, X_val, y_train, y_val, texts_train, texts_val = train_test_split(X, y, texts, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "input_shape = (frames_per_sequence, *image_size, 1)\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "cnn_model = TimeDistributed(Conv2D(32, (3, 3), activation='relu'))(input_layer)\n",
    "cnn_model = TimeDistributed(MaxPooling2D((2, 2)))(cnn_model)\n",
    "cnn_model = TimeDistributed(Conv2D(64, (3, 3), activation='relu'))(cnn_model)\n",
    "cnn_model = TimeDistributed(MaxPooling2D((2, 2)))(cnn_model)\n",
    "cnn_model = TimeDistributed(Conv2D(128, (3, 3), activation='relu'))(cnn_model)\n",
    "cnn_model = TimeDistributed(MaxPooling2D((2, 2)))(cnn_model)\n",
    "cnn_model = TimeDistributed(Flatten())(cnn_model)\n",
    "\n",
    "rnn_model = LSTM(128, return_sequences=False)(cnn_model)\n",
    "rnn_model = Dropout(0.5)(rnn_model)\n",
    " \n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "text_inputs = tokenizer(texts_train, return_tensors='tf', padding=True, truncation=True, max_length=128)\n",
    "input_ids = Input(shape=(128,), dtype=tf.int32, name='input_ids')\n",
    "attention_mask = Input(shape=(128,), dtype=tf.int32, name='attention_mask')\n",
    "\n",
    "bert_outputs = bert_model(input_ids, attention_mask=attention_mask)\n",
    "text_features = bert_outputs.last_hidden_state[:, 0, :]  \n",
    "\n",
    "\n",
    "combined = Concatenate()([rnn_model, text_features])\n",
    "combined = Dense(128, activation='relu')(combined)\n",
    "combined = Dropout(0.5)(combined)\n",
    "output_layer = Dense(num_classes, activation='softmax')(combined)\n",
    "\n",
    "model = Model(inputs=[input_layer, input_ids, attention_mask], outputs=output_layer)\n",
    "\n",
    "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
